{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NYC Trip Fares Project - Fundamentals of Computer Science 24/25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
      "0       1.0  2020-01-01 00:28:15   2020-01-01 00:33:03              1.0   \n",
      "1       1.0  2020-01-01 00:35:39   2020-01-01 00:43:04              1.0   \n",
      "2       1.0  2020-01-01 00:47:41   2020-01-01 00:53:52              1.0   \n",
      "3       1.0  2020-01-01 00:55:23   2020-01-01 01:00:14              1.0   \n",
      "4       2.0  2020-01-01 00:01:58   2020-01-01 00:04:16              1.0   \n",
      "\n",
      "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
      "0            1.2         1.0                  N           238           239   \n",
      "1            1.2         1.0                  N           239           238   \n",
      "2            0.6         1.0                  N           238           238   \n",
      "3            0.8         1.0                  N           238           151   \n",
      "4            0.0         1.0                  N           193           193   \n",
      "\n",
      "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
      "0           1.0          6.0    3.0      0.5        1.47           0.0   \n",
      "1           1.0          7.0    3.0      0.5        1.50           0.0   \n",
      "2           1.0          6.0    3.0      0.5        1.00           0.0   \n",
      "3           1.0          5.5    0.5      0.5        1.36           0.0   \n",
      "4           2.0          3.5    0.5      0.5        0.00           0.0   \n",
      "\n",
      "   improvement_surcharge  total_amount  congestion_surcharge  \n",
      "0                    0.3         11.27                   2.5  \n",
      "1                    0.3         12.30                   2.5  \n",
      "2                    0.3         10.80                   2.5  \n",
      "3                    0.3          8.16                   0.0  \n",
      "4                    0.3          4.80                   0.0  \n"
     ]
    }
   ],
   "source": [
    "file_path = 'NYCTripFares.csv'\n",
    "data = pd.read_csv(file_path, low_memory = False)\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Extract all trips with trip_distance larger than 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
      "23842       2.0  2020-01-01 01:53:07   2020-01-01 03:54:41              1.0   \n",
      "39013       2.0  2020-01-01 02:05:07   2020-01-01 03:03:10              1.0   \n",
      "41620       1.0  2020-01-01 03:05:54   2020-01-01 04:16:26              1.0   \n",
      "58262       2.0  2020-01-01 05:36:12   2020-01-01 06:40:06              1.0   \n",
      "63024       2.0  2020-01-01 07:40:30   2020-01-01 08:40:01              1.0   \n",
      "\n",
      "       trip_distance  RatecodeID store_and_fwd_flag  PULocationID  \\\n",
      "23842          52.30         5.0                  N           262   \n",
      "39013          51.23         5.0                  N           264   \n",
      "41620          53.80         5.0                  N           132   \n",
      "58262          55.23         5.0                  N           132   \n",
      "63024          54.19         5.0                  N           132   \n",
      "\n",
      "       DOLocationID  payment_type  fare_amount  extra  mta_tax  tip_amount  \\\n",
      "23842           265           1.0        300.0    0.0      0.0       61.78   \n",
      "39013           264           1.0        329.0    0.0      0.5      100.78   \n",
      "41620           265           1.0        250.0    0.0      0.0       53.35   \n",
      "58262           265           2.0        170.0    0.0      0.5        0.00   \n",
      "63024           265           1.0        230.0    0.0      0.0        0.00   \n",
      "\n",
      "       tolls_amount  improvement_surcharge  total_amount  congestion_surcharge  \n",
      "23842          6.12                    0.3        370.70                   2.5  \n",
      "39013          6.12                    0.3        436.70                   0.0  \n",
      "41620         16.62                    0.3        320.27                   0.0  \n",
      "58262         18.26                    0.3        189.06                   0.0  \n",
      "63024         12.24                    0.3        242.54                   0.0  \n",
      "Number of trips with trip_distance > 50: 379\n"
     ]
    }
   ],
   "source": [
    "# Extract trips where trip_distance > 50\n",
    "filtered_data = data[data['trip_distance'] > 50]\n",
    "\n",
    "# Display the first few rows of the filtered data\n",
    "print(filtered_data.head())\n",
    "\n",
    "# Display the number of trips with trip_distance > 50\n",
    "print(f\"Number of trips with trip_distance > 50: {len(filtered_data)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Extract all trips where payment_type is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
      "6339567       NaN  2020-01-01 08:51:00   2020-01-01 09:19:00              NaN   \n",
      "6339568       NaN  2020-01-01 08:38:43   2020-01-01 08:51:08              NaN   \n",
      "6339569       NaN  2020-01-01 08:27:00   2020-01-01 08:32:00              NaN   \n",
      "6339570       NaN  2020-01-01 08:46:00   2020-01-01 08:57:00              NaN   \n",
      "6339571       NaN  2020-01-01 08:21:00   2020-01-01 08:38:00              NaN   \n",
      "\n",
      "         trip_distance  RatecodeID store_and_fwd_flag  PULocationID  \\\n",
      "6339567          13.69         NaN                NaN           136   \n",
      "6339568           3.42         NaN                NaN           121   \n",
      "6339569           2.20         NaN                NaN           197   \n",
      "6339570           0.84         NaN                NaN           262   \n",
      "6339571           7.24         NaN                NaN            45   \n",
      "\n",
      "         DOLocationID  payment_type  fare_amount  extra  mta_tax  tip_amount  \\\n",
      "6339567           232           NaN        51.05   2.75      0.5         0.0   \n",
      "6339568             9           NaN        27.06   2.75      0.0         0.0   \n",
      "6339569           216           NaN        24.36   2.75      0.5         0.0   \n",
      "6339570           236           NaN        26.08   2.75      0.5         0.0   \n",
      "6339571           142           NaN        25.28   2.75      0.5         0.0   \n",
      "\n",
      "         tolls_amount  improvement_surcharge  total_amount  \\\n",
      "6339567           0.0                    0.3         54.60   \n",
      "6339568           0.0                    0.3         30.11   \n",
      "6339569           0.0                    0.3         27.91   \n",
      "6339570           0.0                    0.3         29.63   \n",
      "6339571           0.0                    0.3         28.83   \n",
      "\n",
      "         congestion_surcharge  \n",
      "6339567                   0.0  \n",
      "6339568                   0.0  \n",
      "6339569                   0.0  \n",
      "6339570                   0.0  \n",
      "6339571                   0.0  \n",
      "Number of trips with missing payment_type: 65441\n"
     ]
    }
   ],
   "source": [
    "# Extract trips where payment_type is missing (NaN)\n",
    "missing_payment_type = data[data['payment_type'].isna()]\n",
    "\n",
    "# Display the first few rows of the filtered data\n",
    "print(missing_payment_type.head())\n",
    "\n",
    "# Display the number of trips with missing payment_type\n",
    "print(f\"Number of trips with missing payment_type: {len(missing_payment_type)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. For each (PULocationID, DOLocationID) pair, determine the number of trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PULocationID  DOLocationID  trip_count\n",
      "0             1             1         638\n",
      "1             1            50           1\n",
      "2             1            68           1\n",
      "3             1           138           2\n",
      "4             1           140           1\n",
      "5             1           148           1\n",
      "6             1           211           1\n",
      "7             1           231           1\n",
      "8             1           264         105\n",
      "9             1           265           4\n"
     ]
    }
   ],
   "source": [
    "# Group by (PULocationID, DOLocationID) and count trips\n",
    "trip_counts = data.groupby(['PULocationID', 'DOLocationID']).size().reset_index(name='trip_count')\n",
    "\n",
    "# Display the first few rows\n",
    "print(trip_counts.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Save all rows with missing VendorID, passenger_count, store_and_fwd_flag, payment_type in a new dataframe called bad, and remove those rows from the original dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
      "6339567       NaN  2020-01-01 08:51:00   2020-01-01 09:19:00              NaN   \n",
      "6339568       NaN  2020-01-01 08:38:43   2020-01-01 08:51:08              NaN   \n",
      "6339569       NaN  2020-01-01 08:27:00   2020-01-01 08:32:00              NaN   \n",
      "6339570       NaN  2020-01-01 08:46:00   2020-01-01 08:57:00              NaN   \n",
      "6339571       NaN  2020-01-01 08:21:00   2020-01-01 08:38:00              NaN   \n",
      "\n",
      "         trip_distance  RatecodeID store_and_fwd_flag  PULocationID  \\\n",
      "6339567          13.69         NaN                NaN           136   \n",
      "6339568           3.42         NaN                NaN           121   \n",
      "6339569           2.20         NaN                NaN           197   \n",
      "6339570           0.84         NaN                NaN           262   \n",
      "6339571           7.24         NaN                NaN            45   \n",
      "\n",
      "         DOLocationID  payment_type  fare_amount  extra  mta_tax  tip_amount  \\\n",
      "6339567           232           NaN        51.05   2.75      0.5         0.0   \n",
      "6339568             9           NaN        27.06   2.75      0.0         0.0   \n",
      "6339569           216           NaN        24.36   2.75      0.5         0.0   \n",
      "6339570           236           NaN        26.08   2.75      0.5         0.0   \n",
      "6339571           142           NaN        25.28   2.75      0.5         0.0   \n",
      "\n",
      "         tolls_amount  improvement_surcharge  total_amount  \\\n",
      "6339567           0.0                    0.3         54.60   \n",
      "6339568           0.0                    0.3         30.11   \n",
      "6339569           0.0                    0.3         27.91   \n",
      "6339570           0.0                    0.3         29.63   \n",
      "6339571           0.0                    0.3         28.83   \n",
      "\n",
      "         congestion_surcharge  \n",
      "6339567                   0.0  \n",
      "6339568                   0.0  \n",
      "6339569                   0.0  \n",
      "6339570                   0.0  \n",
      "6339571                   0.0  \n",
      "Number of rows in 'bad': 65441\n",
      "Number of rows in 'data' after removal: 6339567\n"
     ]
    }
   ],
   "source": [
    "# Identify rows with missing values in specified columns\n",
    "columns_to_check = ['VendorID', 'passenger_count', 'store_and_fwd_flag', 'payment_type']\n",
    "bad = data[data[columns_to_check].isna().any(axis=1)]\n",
    "\n",
    "# Display the first few rows of the 'bad' DataFrame\n",
    "print(bad.head())\n",
    "\n",
    "# Remove these rows from the original DataFrame\n",
    "data = data.drop(bad.index)\n",
    "\n",
    "# Display the shapes of the resulting DataFrames for verification\n",
    "print(f\"Number of rows in 'bad': {len(bad)}\")\n",
    "print(f\"Number of rows in 'data' after removal: {len(data)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Add a duration column storing how long each trip has taken (use tpep_pickup_datetime, tpep_dropoff_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  tpep_pickup_datetime tpep_dropoff_datetime  duration\n",
      "0  2020-01-01 00:28:15   2020-01-01 00:33:03  4.800000\n",
      "1  2020-01-01 00:35:39   2020-01-01 00:43:04  7.416667\n",
      "2  2020-01-01 00:47:41   2020-01-01 00:53:52  6.183333\n",
      "3  2020-01-01 00:55:23   2020-01-01 01:00:14  4.850000\n",
      "4  2020-01-01 00:01:58   2020-01-01 00:04:16  2.300000\n",
      "Number of invalid durations: 4147\n"
     ]
    }
   ],
   "source": [
    "# Ensure the datetime columns are in datetime format\n",
    "data['tpep_pickup_datetime'] = pd.to_datetime(data['tpep_pickup_datetime'])\n",
    "data['tpep_dropoff_datetime'] = pd.to_datetime(data['tpep_dropoff_datetime'])\n",
    "\n",
    "# Calculate the duration in minutes\n",
    "data['duration'] = (data['tpep_dropoff_datetime'] - data['tpep_pickup_datetime']).dt.total_seconds() / 60\n",
    "\n",
    "# Display the first few rows with the new duration column\n",
    "print(data[['tpep_pickup_datetime', 'tpep_dropoff_datetime', 'duration']].head())\n",
    "\n",
    "# Check for any negative or zero durations (potential data issues)\n",
    "invalid_durations = data[data['duration'] <= 0]\n",
    "print(f\"Number of invalid durations: {len(invalid_durations)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. For each pickup location, determine how many trips have started there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PULocationID  trip_count\n",
      "0             1         753\n",
      "1             2           3\n",
      "2             3          70\n",
      "3             4        9902\n",
      "4             5          39\n",
      "     PULocationID  trip_count\n",
      "231           237      292467\n",
      "156           161      281545\n",
      "230           236      271999\n",
      "157           162      235024\n",
      "181           186      228231\n",
      "224           230      227944\n",
      "127           132      214133\n",
      "165           170      193777\n",
      "46             48      193365\n",
      "137           142      193054\n"
     ]
    }
   ],
   "source": [
    "# Group by PULocationID and count the number of trips\n",
    "pickup_counts = data.groupby('PULocationID').size().reset_index(name='trip_count')\n",
    "\n",
    "# Display the first few rows of the result\n",
    "print(pickup_counts.head())\n",
    "\n",
    "# Optional: Sort the results by the number of trips in descending order\n",
    "sorted_pickup_counts = pickup_counts.sort_values(by='trip_count', ascending=False)\n",
    "\n",
    "# Display the top 10 pickup locations with the most trips\n",
    "print(sorted_pickup_counts.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Cluster the pickup time of the day into 30-minute intervals (e.g. from 02:00 to 02:30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  tpep_pickup_datetime     pickup_interval\n",
      "0  2020-01-01 00:28:15 2020-01-01 00:00:00\n",
      "1  2020-01-01 00:35:39 2020-01-01 00:30:00\n",
      "2  2020-01-01 00:47:41 2020-01-01 00:30:00\n",
      "3  2020-01-01 00:55:23 2020-01-01 00:30:00\n",
      "4  2020-01-01 00:01:58 2020-01-01 00:00:00\n",
      "      pickup_interval  trip_count\n",
      "0 2003-01-01 00:00:00           1\n",
      "1 2008-12-31 23:00:00           7\n",
      "2 2008-12-31 23:30:00           3\n",
      "3 2009-01-01 00:00:00           9\n",
      "4 2009-01-01 00:30:00           4\n"
     ]
    }
   ],
   "source": [
    "# Extract the time of day from tpep_pickup_datetime\n",
    "data['pickup_time'] = data['tpep_pickup_datetime'].dt.time\n",
    "\n",
    "# Round pickup times to the nearest 30-minute interval\n",
    "data['pickup_interval'] = data['tpep_pickup_datetime'].dt.floor('30min')\n",
    "\n",
    "# Display the first few rows with the new column\n",
    "print(data[['tpep_pickup_datetime', 'pickup_interval']].head())\n",
    "\n",
    "# Optional: Count the number of trips in each interval\n",
    "interval_counts = data.groupby('pickup_interval').size().reset_index(name='trip_count')\n",
    "\n",
    "# Display the first few rows of the interval counts\n",
    "print(interval_counts.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. For each interval, determine the average number of passengers and the average fare amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      pickup_interval  avg_passengers   avg_fare\n",
      "0 2003-01-01 00:00:00        1.000000   0.000000\n",
      "1 2008-12-31 23:00:00        2.000000  18.857143\n",
      "2 2008-12-31 23:30:00        1.000000  22.666667\n",
      "3 2009-01-01 00:00:00        1.777778  25.166667\n",
      "4 2009-01-01 00:30:00        2.000000  24.250000\n",
      "         pickup_interval  avg_passengers   avg_fare\n",
      "19   2019-12-31 18:00:00        1.000000  52.000000\n",
      "18   2019-12-31 17:30:00        1.000000  47.500000\n",
      "1515 2020-02-01 00:00:00        1.416667  25.978750\n",
      "3    2009-01-01 00:00:00        1.777778  25.166667\n",
      "4    2009-01-01 00:30:00        2.000000  24.250000\n"
     ]
    }
   ],
   "source": [
    "# Group by pickup_interval and calculate average passengers and fare amount\n",
    "interval_averages = data.groupby('pickup_interval').agg(\n",
    "    avg_passengers=('passenger_count', 'mean'),\n",
    "    avg_fare=('fare_amount', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "# Display the first few rows of the results\n",
    "print(interval_averages.head())\n",
    "\n",
    "# Optional: Sort by average fare or average passengers if needed\n",
    "sorted_intervals = interval_averages.sort_values(by='avg_fare', ascending=False)\n",
    "\n",
    "# Display the top intervals with the highest average fare\n",
    "print(sorted_intervals.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. For each payment type and each interval, determine the average fare amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   payment_type     pickup_interval  avg_fare\n",
      "0           1.0 2008-12-31 23:00:00     13.50\n",
      "1           1.0 2008-12-31 23:30:00     52.00\n",
      "2           1.0 2009-01-01 00:00:00     15.00\n",
      "3           1.0 2019-12-18 15:00:00      0.01\n",
      "4           1.0 2019-12-18 15:30:00      2.50\n",
      "      payment_type     pickup_interval   avg_fare\n",
      "5591           4.0 2020-01-23 05:00:00  83.800000\n",
      "1              1.0 2008-12-31 23:30:00  52.000000\n",
      "5111           4.0 2020-01-13 04:30:00  52.000000\n",
      "11             1.0 2019-12-31 18:00:00  52.000000\n",
      "10             1.0 2019-12-31 17:30:00  47.500000\n",
      "3766           3.0 2020-01-16 03:30:00  45.800000\n",
      "5018           4.0 2020-01-11 06:00:00  39.625000\n",
      "4585           4.0 2020-01-02 05:30:00  36.933333\n",
      "4894           4.0 2020-01-08 16:00:00  36.686111\n",
      "4394           3.0 2020-01-29 05:30:00  34.900000\n"
     ]
    }
   ],
   "source": [
    "# Group by payment_type and pickup_interval, then calculate the average fare amount\n",
    "payment_interval_averages = data.groupby(['payment_type', 'pickup_interval']).agg(\n",
    "    avg_fare=('fare_amount', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "# Display the first few rows of the results\n",
    "print(payment_interval_averages.head())\n",
    "\n",
    "# Optional: Sort by average fare amount in descending order\n",
    "sorted_payment_interval = payment_interval_averages.sort_values(by='avg_fare', ascending=False)\n",
    "\n",
    "# Display the top combinations with the highest average fare\n",
    "print(sorted_payment_interval.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. For each payment type, determine the interval when the average fare amount is maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      payment_type     pickup_interval  avg_fare\n",
      "1              1.0 2008-12-31 23:30:00   52.0000\n",
      "1527           2.0 2009-01-01 00:00:00   26.4375\n",
      "3766           3.0 2020-01-16 03:30:00   45.8000\n",
      "5591           4.0 2020-01-23 05:00:00   83.8000\n",
      "6011           5.0 2020-01-21 17:30:00    0.0000\n"
     ]
    }
   ],
   "source": [
    "# Group by payment_type and pickup_interval, then calculate the average fare amount\n",
    "payment_interval_averages = data.groupby(['payment_type', 'pickup_interval']).agg(\n",
    "    avg_fare=('fare_amount', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "# Find the interval with the maximum average fare for each payment type\n",
    "max_fare_intervals = payment_interval_averages.loc[\n",
    "    payment_interval_averages.groupby('payment_type')['avg_fare'].idxmax()\n",
    "]\n",
    "\n",
    "# Display the results\n",
    "print(max_fare_intervals)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. For each payment type, determine the interval when the overall ratio between the tip and the fare amounts is maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      payment_type     pickup_interval  avg_tip_fare_ratio\n",
      "310            1.0 2020-01-07 01:30:00           26.446845\n",
      "2903           2.0 2020-01-29 09:00:00            0.001165\n",
      "3079           3.0 2020-01-01 21:00:00            1.230769\n",
      "5854           4.0 2020-01-29 10:00:00            0.131667\n"
     ]
    }
   ],
   "source": [
    "# Ensure no division by zero\n",
    "data = data[data['fare_amount'] > 0]\n",
    "\n",
    "# Calculate the tip-to-fare ratio\n",
    "data['tip_fare_ratio'] = data['tip_amount'] / data['fare_amount']\n",
    "\n",
    "# Group by payment_type and pickup_interval, then calculate the average tip-to-fare ratio\n",
    "payment_interval_ratios = data.groupby(['payment_type', 'pickup_interval']).agg(\n",
    "    avg_tip_fare_ratio=('tip_fare_ratio', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "# Find the interval with the maximum average tip-to-fare ratio for each payment type\n",
    "max_ratio_intervals = payment_interval_ratios.loc[\n",
    "    payment_interval_ratios.groupby('payment_type')['avg_tip_fare_ratio'].idxmax()\n",
    "]\n",
    "\n",
    "# Display the results\n",
    "print(max_ratio_intervals)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Find the location with the highest average fare amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location with the highest average fare amount:\n",
      "LocationID    150-265\n",
      "avg_fare        317.5\n",
      "Name: 5992, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Combine pickup and drop-off locations into a single column\n",
    "data['LocationID'] = data['PULocationID'].astype(str) + '-' + data['DOLocationID'].astype(str)\n",
    "\n",
    "# Group by LocationID and calculate the average fare amount\n",
    "location_avg_fare = data.groupby('LocationID').agg(\n",
    "    avg_fare=('fare_amount', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "# Find the location with the highest average fare\n",
    "highest_avg_fare_location = location_avg_fare.loc[location_avg_fare['avg_fare'].idxmax()]\n",
    "\n",
    "# Display the result\n",
    "print(\"Location with the highest average fare amount:\")\n",
    "print(highest_avg_fare_location)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. Build a new dataframe (called common) where, for each pickup location we keep all trips to the 5 most common destinations (i.e. each pickup location can have different common destinations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Inna\\AppData\\Local\\Temp\\ipykernel_16864\\3142015980.py:5: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  top_destinations = trip_counts.groupby('PULocationID').apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
      "0       1.0  2020-01-01 00:28:15   2020-01-01 00:33:03              1.0   \n",
      "1       1.0  2020-01-01 00:35:39   2020-01-01 00:43:04              1.0   \n",
      "2       1.0  2020-01-01 00:47:41   2020-01-01 00:53:52              1.0   \n",
      "3       1.0  2020-01-01 00:55:23   2020-01-01 01:00:14              1.0   \n",
      "4       2.0  2020-01-01 00:01:58   2020-01-01 00:04:16              1.0   \n",
      "\n",
      "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
      "0            1.2         1.0                  N           238           239   \n",
      "1            1.2         1.0                  N           239           238   \n",
      "2            0.6         1.0                  N           238           238   \n",
      "3            0.8         1.0                  N           238           151   \n",
      "4            0.0         1.0                  N           193           193   \n",
      "\n",
      "   payment_type  ...  tip_amount  tolls_amount  improvement_surcharge  \\\n",
      "0           1.0  ...        1.47           0.0                    0.3   \n",
      "1           1.0  ...        1.50           0.0                    0.3   \n",
      "2           1.0  ...        1.00           0.0                    0.3   \n",
      "3           1.0  ...        1.36           0.0                    0.3   \n",
      "4           2.0  ...        0.00           0.0                    0.3   \n",
      "\n",
      "   total_amount  congestion_surcharge  duration  pickup_time  \\\n",
      "0         11.27                   2.5  4.800000     00:28:15   \n",
      "1         12.30                   2.5  7.416667     00:35:39   \n",
      "2         10.80                   2.5  6.183333     00:47:41   \n",
      "3          8.16                   0.0  4.850000     00:55:23   \n",
      "4          4.80                   0.0  2.300000     00:01:58   \n",
      "\n",
      "      pickup_interval  tip_fare_ratio LocationID  \n",
      "0 2020-01-01 00:00:00        0.245000    238-239  \n",
      "1 2020-01-01 00:30:00        0.214286    239-238  \n",
      "2 2020-01-01 00:30:00        0.166667    238-238  \n",
      "3 2020-01-01 00:30:00        0.247273    238-151  \n",
      "4 2020-01-01 00:00:00        0.000000    193-193  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "Number of rows in the 'common' DataFrame: 1944997\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Count the number of trips for each (PULocationID, DOLocationID) pair\n",
    "trip_counts = data.groupby(['PULocationID', 'DOLocationID']).size().reset_index(name='trip_count')\n",
    "\n",
    "# Step 2: Find the top 5 destinations for each pickup location\n",
    "top_destinations = trip_counts.groupby('PULocationID').apply(\n",
    "    lambda x: x.nlargest(5, 'trip_count')\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Step 3: Filter the original dataset to keep only trips to the top 5 destinations for each pickup location\n",
    "common = data.merge(\n",
    "    top_destinations[['PULocationID', 'DOLocationID']],\n",
    "    on=['PULocationID', 'DOLocationID'],\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Display the first few rows of the common DataFrame\n",
    "print(common.head())\n",
    "\n",
    "# Display the number of rows in the common DataFrame\n",
    "print(f\"Number of rows in the 'common' DataFrame: {len(common)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. On the common dataframe, for each payment type and each interval, determine the average fare amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   payment_type     pickup_interval  avg_fare\n",
      "0           1.0 2008-12-31 23:00:00      6.00\n",
      "1           1.0 2019-12-18 15:00:00      0.01\n",
      "2           1.0 2019-12-18 15:30:00      2.50\n",
      "3           1.0 2019-12-31 14:00:00      6.00\n",
      "4           1.0 2019-12-31 16:30:00      7.00\n",
      "      payment_type     pickup_interval    avg_fare\n",
      "5297           4.0 2020-01-23 05:00:00  201.500000\n",
      "4616           4.0 2020-01-05 17:30:00  144.833333\n",
      "4727           4.0 2020-01-08 16:00:00  138.070000\n",
      "5137           4.0 2020-01-18 22:00:00  116.500000\n",
      "3698           3.0 2020-01-16 03:30:00  110.500000\n",
      "5347           4.0 2020-01-24 09:00:00  100.000000\n",
      "4923           4.0 2020-01-13 14:00:00   97.000000\n",
      "3741           3.0 2020-01-17 01:30:00   80.900000\n",
      "4473           4.0 2020-01-01 22:30:00   71.420000\n",
      "4777           4.0 2020-01-09 21:30:00   67.285714\n"
     ]
    }
   ],
   "source": [
    "# Group by payment_type and pickup_interval, then calculate the average fare amount\n",
    "common_payment_interval_averages = common.groupby(['payment_type', 'pickup_interval']).agg(\n",
    "    avg_fare=('fare_amount', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "# Display the first few rows of the result\n",
    "print(common_payment_interval_averages.head())\n",
    "\n",
    "# Optional: Sort the result by average fare amount\n",
    "sorted_common_averages = common_payment_interval_averages.sort_values(by='avg_fare', ascending=False)\n",
    "\n",
    "# Display the top 10 results\n",
    "print(sorted_common_averages.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. Compute the difference of the average fare amount computed in the previous point with those computed at point 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   payment_type     pickup_interval  avg_fare_common  avg_fare_all  \\\n",
      "0           1.0 2008-12-31 23:00:00             6.00         13.50   \n",
      "1           1.0 2019-12-18 15:00:00             0.01          0.01   \n",
      "2           1.0 2019-12-18 15:30:00             2.50          2.50   \n",
      "3           1.0 2019-12-31 14:00:00             6.00         12.75   \n",
      "4           1.0 2019-12-31 16:30:00             7.00          7.00   \n",
      "\n",
      "   fare_difference  \n",
      "0            -7.50  \n",
      "1             0.00  \n",
      "2             0.00  \n",
      "3            -6.75  \n",
      "4             0.00  \n",
      "      payment_type     pickup_interval  avg_fare_common  avg_fare_all  \\\n",
      "4616           4.0 2020-01-05 17:30:00       144.833333     20.941176   \n",
      "3653           3.0 2020-01-15 05:00:00         4.500000   -114.875000   \n",
      "5297           4.0 2020-01-23 05:00:00       201.500000     83.800000   \n",
      "5219           4.0 2020-01-21 01:00:00         3.000000   -102.428571   \n",
      "4727           4.0 2020-01-08 16:00:00       138.070000     36.686111   \n",
      "5137           4.0 2020-01-18 22:00:00       116.500000     16.550000   \n",
      "5347           4.0 2020-01-24 09:00:00       100.000000      4.666667   \n",
      "4923           4.0 2020-01-13 14:00:00        97.000000     11.447368   \n",
      "3698           3.0 2020-01-16 03:30:00       110.500000     45.800000   \n",
      "4473           4.0 2020-01-01 22:30:00        71.420000      9.177500   \n",
      "\n",
      "      fare_difference  \n",
      "4616       123.892157  \n",
      "3653       119.375000  \n",
      "5297       117.700000  \n",
      "5219       105.428571  \n",
      "4727       101.383889  \n",
      "5137        99.950000  \n",
      "5347        95.333333  \n",
      "4923        85.552632  \n",
      "3698        64.700000  \n",
      "4473        62.242500  \n"
     ]
    }
   ],
   "source": [
    "# Merge the two DataFrames (from Question 14 and Question 9) on payment_type and pickup_interval\n",
    "fare_comparison = common_payment_interval_averages.merge(\n",
    "    payment_interval_averages,  # From Question 9\n",
    "    on=['payment_type', 'pickup_interval'],\n",
    "    suffixes=('_common', '_all')\n",
    ")\n",
    "\n",
    "# Compute the difference in average fare amounts\n",
    "fare_comparison['fare_difference'] = (\n",
    "    fare_comparison['avg_fare_common'] - fare_comparison['avg_fare_all']\n",
    ")\n",
    "\n",
    "# Display the first few rows of the result\n",
    "print(fare_comparison.head())\n",
    "\n",
    "# Optional: Sort by the largest differences\n",
    "sorted_fare_comparison = fare_comparison.sort_values(by='fare_difference', ascending=False)\n",
    "\n",
    "# Display the top 10 largest differences\n",
    "print(sorted_fare_comparison.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16. Compute the ratio between the differences computed in the previous point and those computed in point 9. Note: you have to compute a ratio for each pair (payment type, interval)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   payment_type     pickup_interval  fare_difference  avg_fare_all  fare_ratio\n",
      "0           1.0 2008-12-31 23:00:00            -7.50         13.50   -0.555556\n",
      "1           1.0 2019-12-18 15:00:00             0.00          0.01    0.000000\n",
      "2           1.0 2019-12-18 15:30:00             0.00          2.50    0.000000\n",
      "3           1.0 2019-12-31 14:00:00            -6.75         12.75   -0.529412\n",
      "4           1.0 2019-12-31 16:30:00             0.00          7.00    0.000000\n",
      "      payment_type     pickup_interval  avg_fare_common  avg_fare_all  \\\n",
      "3053           3.0 2020-01-02 01:30:00            2.500      0.000000   \n",
      "5572           4.0 2020-01-29 20:00:00            9.250      0.000000   \n",
      "4474           4.0 2020-01-01 23:00:00           20.250      0.050000   \n",
      "4511           4.0 2020-01-02 23:30:00            6.000      0.045455   \n",
      "5154           4.0 2020-01-19 10:30:00            5.000      0.045455   \n",
      "4961           4.0 2020-01-14 14:30:00           15.302      0.184737   \n",
      "5092           4.0 2020-01-17 18:00:00            5.125      0.074074   \n",
      "5629           4.0 2020-01-31 04:30:00           27.600      0.400000   \n",
      "4975           4.0 2020-01-14 22:00:00            8.750      0.142857   \n",
      "4758           4.0 2020-01-09 12:00:00            5.500      0.107143   \n",
      "\n",
      "      fare_difference  fare_ratio  \n",
      "3053         2.500000         inf  \n",
      "5572         9.250000         inf  \n",
      "4474        20.200000  404.000000  \n",
      "4511         5.954545  131.000000  \n",
      "5154         4.954545  109.000000  \n",
      "4961        15.117263   81.831339  \n",
      "5092         5.050926   68.187500  \n",
      "5629        27.200000   68.000000  \n",
      "4975         8.607143   60.250000  \n",
      "4758         5.392857   50.333333  \n"
     ]
    }
   ],
   "source": [
    "# Compute the ratio between the differences and the average fare amount from Question 9\n",
    "fare_comparison['fare_ratio'] = fare_comparison['fare_difference'] / fare_comparison['avg_fare_all']\n",
    "\n",
    "# Display the first few rows of the result\n",
    "print(fare_comparison[['payment_type', 'pickup_interval', 'fare_difference', 'avg_fare_all', 'fare_ratio']].head())\n",
    "\n",
    "# Optional: Sort by the largest ratios\n",
    "sorted_fare_ratios = fare_comparison.sort_values(by='fare_ratio', ascending=False)\n",
    "\n",
    "# Display the top 10 largest ratios\n",
    "print(sorted_fare_ratios.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17. Build chains of trips. Two trips are consecutive in a chain if (a) they have the same VendorID, (b) the pickup location of the second trip is also the dropoff location of the first trip, (c) the pickup time of the second trip is after the dropoff time of the first trip, and (d) the pickup time of the second trip is at most 2 minutes later than the dropoff time of the first trip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       VendorID  PULocationID  DOLocationID tpep_pickup_datetime  \\\n",
      "1487        1.0            79            79  2020-01-01 00:01:40   \n",
      "10545       1.0           158           158  2020-01-01 00:00:50   \n",
      "5050        1.0            75            75  2020-01-01 00:00:07   \n",
      "7236        1.0           141           140  2020-01-01 00:01:55   \n",
      "12297       1.0           236           236  2020-01-01 00:01:01   \n",
      "\n",
      "      tpep_dropoff_datetime  chain  \n",
      "1487    2020-01-01 00:01:52    1.0  \n",
      "10545   2020-01-01 00:02:32    2.0  \n",
      "5050    2020-01-01 00:03:26    3.0  \n",
      "7236    2020-01-01 00:04:34    4.0  \n",
      "12297   2020-01-01 00:04:46    5.0  \n"
     ]
    }
   ],
   "source": [
    "# Step 1: Sort the dataset by VendorID, tpep_dropoff_datetime, and tpep_pickup_datetime\n",
    "data = data.sort_values(by=['VendorID', 'tpep_dropoff_datetime', 'tpep_pickup_datetime'])\n",
    "\n",
    "# Step 2: Add a column to store the chain ID, initialize it with NaN\n",
    "data['chain'] = np.nan\n",
    "\n",
    "# Step 3: Iterate through the dataset to build chains\n",
    "chain_id = 0  # Initialize chain ID\n",
    "prev_row = None  # Store the previous row to check chain conditions\n",
    "\n",
    "for idx, row in data.iterrows():\n",
    "    if prev_row is not None:\n",
    "        # Check conditions for chain\n",
    "        same_vendor = row['VendorID'] == prev_row['VendorID']\n",
    "        matching_locations = row['PULocationID'] == prev_row['DOLocationID']\n",
    "        time_difference = (row['tpep_pickup_datetime'] - prev_row['tpep_dropoff_datetime']).total_seconds()\n",
    "\n",
    "        if same_vendor and matching_locations and 0 < time_difference <= 120:\n",
    "            # Part of the same chain, inherit the previous chain ID\n",
    "            data.at[idx, 'chain'] = chain_id\n",
    "        else:\n",
    "            # Not part of the same chain, assign a new chain ID\n",
    "            chain_id += 1\n",
    "            data.at[idx, 'chain'] = chain_id\n",
    "    else:\n",
    "        # First row, assign initial chain ID\n",
    "        chain_id += 1\n",
    "        data.at[idx, 'chain'] = chain_id\n",
    "\n",
    "    # Update the previous row\n",
    "    prev_row = row\n",
    "\n",
    "# Display the dataset with the new chain column\n",
    "print(data[['VendorID', 'PULocationID', 'DOLocationID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime', 'chain']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
